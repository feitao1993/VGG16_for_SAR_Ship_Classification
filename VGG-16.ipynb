{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all the necessary modules\n",
    "Make a conda environment and install Tensorflow 1.9.0, keras 2.1.6, OpenCV, and sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import optimizers, regularizers\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy import misc, ndimage\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lock the Random variables\n",
    ".seed functions allow us to reproduce the same results for each random initialization\n",
    "If the seed is set to the same number each time the program is run then the results of training the model will be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = '0' \n",
    "np.random.seed(10)\n",
    "random.seed(10)\n",
    "tf.set_random_seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helper function below for plotting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(ims, figsize = (12,6), rows = 1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize = figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to directories containing the image data, and the list of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"/home/hamza/hamzamk/Keras_work/Ship_images\"\n",
    "#categories1 = [\"cargo_RGB\", \"dredging_RGB\",  \"fishing_RGB\",  \"tanker_RGB\",  \"tug_RGB\"]\n",
    "categories = [\"cargo\", \"tanker\", \"others\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/hamza/hamzamk/Keras_work/Ship_images/train'\n",
    "valid_path = '/home/hamza/hamzamk/Keras_work/Ship_images/valid'\n",
    "test_path = '/home/hamza/hamzamk/Keras_work/Ship_images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11269 images belonging to 3 classes.\n",
      "Found 140 images belonging to 3 classes.\n",
      "Found 21 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size = (224, 224), color_mode='rgb', classes = categories, batch_size = 32, shuffle=True)\n",
    "valid_batches = ImageDataGenerator().flow_from_directory(valid_path, target_size = (224, 224), color_mode='rgb',  classes = categories, batch_size = 30, shuffle=True)\n",
    "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size = (224, 224),  color_mode='rgb', classes = categories, batch_size = 27, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the indices or lables assigned to each class by the ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cargo': 0, 'tanker': 1, 'others': 2}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_imgs, test_labels = next(test_batches)\n",
    "class_labels = test_batches.class_indices\n",
    "class_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and check its structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model = keras.applications.vgg16.VGG16()\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.training.Model"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vgg16_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing VGG16\n",
    "iterate over the layers to feed the sequential model, set trainable to False to benefit from the pre-trained weights.\n",
    "Add layers to the model for fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers = []\n",
    "for layer in vgg16_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "    layers.append(layer)\n",
    "\n",
    "model = Sequential(layers + [\n",
    "    Conv2D(filters = 512, kernel_size = (7, 7), activation = 'relu'),\n",
    "    #Conv2D(filters = 512, kernel_size = (4,4), activation = 'relu'),\n",
    "    Flatten(),\n",
    "    BatchNormalization(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(2048, activation = 'relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(3, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 1, 1, 512)         12845568  \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 2048)              8390656   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 3)                 6147      \n",
      "=================================================================\n",
      "Total params: 38,060,355\n",
      "Trainable params: 23,344,643\n",
      "Non-trainable params: 14,715,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Compilation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adam = optimizers.Adam(lr=0.0001)\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33\n",
      "353/353 [==============================] - 42s 119ms/step - loss: 0.7930 - acc: 0.7397 - val_loss: 0.8273 - val_acc: 0.6429\n",
      "Epoch 2/33\n",
      "353/353 [==============================] - 39s 112ms/step - loss: 0.6137 - acc: 0.7603 - val_loss: 1.2094 - val_acc: 0.6857\n",
      "Epoch 3/33\n",
      "353/353 [==============================] - 39s 112ms/step - loss: 0.5758 - acc: 0.7730 - val_loss: 0.7135 - val_acc: 0.7143\n",
      "Epoch 4/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.5328 - acc: 0.7837 - val_loss: 0.7206 - val_acc: 0.7071\n",
      "Epoch 5/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.4856 - acc: 0.8006 - val_loss: 0.8780 - val_acc: 0.6786\n",
      "Epoch 6/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.4331 - acc: 0.8235 - val_loss: 0.9285 - val_acc: 0.7000\n",
      "Epoch 7/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.3866 - acc: 0.8418 - val_loss: 1.2975 - val_acc: 0.6857\n",
      "Epoch 8/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.3514 - acc: 0.8597 - val_loss: 0.7133 - val_acc: 0.7714\n",
      "Epoch 9/33\n",
      "353/353 [==============================] - 40s 114ms/step - loss: 0.3139 - acc: 0.8713 - val_loss: 1.1082 - val_acc: 0.7214\n",
      "Epoch 10/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.2947 - acc: 0.8838 - val_loss: 0.7118 - val_acc: 0.8571\n",
      "Epoch 11/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.2541 - acc: 0.9006 - val_loss: 0.9337 - val_acc: 0.7500\n",
      "Epoch 12/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.2205 - acc: 0.9127 - val_loss: 0.7958 - val_acc: 0.8143\n",
      "Epoch 13/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.2084 - acc: 0.9175 - val_loss: 0.9217 - val_acc: 0.7500\n",
      "Epoch 14/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.1774 - acc: 0.9324 - val_loss: 1.0757 - val_acc: 0.7857\n",
      "Epoch 15/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.1742 - acc: 0.9352 - val_loss: 1.2061 - val_acc: 0.7643\n",
      "Epoch 16/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.1552 - acc: 0.9440 - val_loss: 0.9616 - val_acc: 0.8643\n",
      "Epoch 17/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.1449 - acc: 0.9486 - val_loss: 0.8712 - val_acc: 0.8214\n",
      "Epoch 18/33\n",
      "353/353 [==============================] - 40s 112ms/step - loss: 0.1259 - acc: 0.9554 - val_loss: 0.9133 - val_acc: 0.8500\n",
      "Epoch 19/33\n",
      "353/353 [==============================] - 40s 112ms/step - loss: 0.1013 - acc: 0.9626 - val_loss: 0.9651 - val_acc: 0.8643\n",
      "Epoch 20/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.1025 - acc: 0.9645 - val_loss: 1.6993 - val_acc: 0.7429\n",
      "Epoch 21/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.1025 - acc: 0.9623 - val_loss: 1.4578 - val_acc: 0.7857\n",
      "Epoch 22/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.0868 - acc: 0.9715 - val_loss: 0.9134 - val_acc: 0.8786\n",
      "Epoch 23/33\n",
      "353/353 [==============================] - 40s 112ms/step - loss: 0.1013 - acc: 0.9628 - val_loss: 1.2139 - val_acc: 0.8214\n",
      "Epoch 24/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.0770 - acc: 0.9719 - val_loss: 0.9158 - val_acc: 0.8500\n",
      "Epoch 25/33\n",
      "353/353 [==============================] - 40s 112ms/step - loss: 0.0748 - acc: 0.9737 - val_loss: 0.8138 - val_acc: 0.8500\n",
      "Epoch 26/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.0737 - acc: 0.9744 - val_loss: 1.2583 - val_acc: 0.8000\n",
      "Epoch 27/33\n",
      "353/353 [==============================] - 40s 112ms/step - loss: 0.0618 - acc: 0.9773 - val_loss: 1.1822 - val_acc: 0.8214\n",
      "Epoch 28/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.0518 - acc: 0.9818 - val_loss: 1.4570 - val_acc: 0.8000\n",
      "Epoch 29/33\n",
      "353/353 [==============================] - 40s 112ms/step - loss: 0.0584 - acc: 0.9803 - val_loss: 1.4994 - val_acc: 0.8071\n",
      "Epoch 30/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.0596 - acc: 0.9798 - val_loss: 2.2629 - val_acc: 0.7714\n",
      "Epoch 31/33\n",
      "353/353 [==============================] - 40s 113ms/step - loss: 0.0605 - acc: 0.9796 - val_loss: 1.5843 - val_acc: 0.7643\n",
      "Epoch 32/33\n",
      "353/353 [==============================] - 40s 112ms/step - loss: 0.0771 - acc: 0.9715 - val_loss: 1.5788 - val_acc: 0.7929\n",
      "Epoch 33/33\n",
      "353/353 [==============================] - 40s 112ms/step - loss: 0.0625 - acc: 0.9800 - val_loss: 1.0963 - val_acc: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5de8d585c0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_batches,\n",
    "                   validation_data = valid_batches,\n",
    "                   shuffle = True,\n",
    "                   epochs = 33,\n",
    "                   verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on test data for Predictions\n",
    "The predictions will be displayed in scientific notation, e.g. 9.9989974e-01 in decimal is 0.99. This indicates high probability for the detected object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 92ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(test_batches, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block below will only work if HTML and display have been imported in the first block, This will allow us to use CSS formating for comparitive content display on jupyter notebook. For viewing normal outputs, use the print function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output{\n",
       "    flex-direction: row;\n",
       "    \n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSS = \"\"\"\n",
    ".output{\n",
    "    flex-direction: row;\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "HTML('<style>{}</style>'.format(CSS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 3.4775942e-13, 6.6274785e-14],\n",
       "       [9.9989164e-01, 6.3697502e-05, 4.4652970e-05],\n",
       "       [1.2284192e-12, 6.6942430e-17, 1.0000000e+00],\n",
       "       [9.9999940e-01, 2.5595641e-09, 5.6758427e-07],\n",
       "       [7.0012698e-06, 2.1521750e-05, 9.9997151e-01],\n",
       "       [1.0000000e+00, 2.8495106e-12, 1.5433321e-13],\n",
       "       [4.2807125e-03, 9.9562114e-01, 9.8098579e-05],\n",
       "       [8.4755355e-03, 9.0063903e-03, 9.8251814e-01],\n",
       "       [2.1089415e-01, 2.8712308e-01, 5.0198275e-01],\n",
       "       [9.9913728e-01, 7.8021281e-04, 8.2476043e-05],\n",
       "       [4.9707349e-10, 4.8635895e-09, 1.0000000e+00],\n",
       "       [1.6808770e-05, 1.5966411e-05, 9.9996722e-01],\n",
       "       [9.9999809e-01, 1.9224613e-06, 9.1206225e-09],\n",
       "       [9.3211513e-03, 3.1096300e-01, 6.7971587e-01],\n",
       "       [1.0000000e+00, 1.1235273e-17, 7.6910443e-18],\n",
       "       [3.7214268e-04, 9.9769896e-01, 1.9288961e-03],\n",
       "       [1.4195481e-06, 9.9985862e-01, 1.3999132e-04],\n",
       "       [2.1005847e-07, 2.3376676e-06, 9.9999750e-01],\n",
       "       [2.3687346e-06, 9.7879114e-05, 9.9989974e-01],\n",
       "       [1.0792441e-02, 3.0010276e-02, 9.5919728e-01],\n",
       "       [2.5436091e-01, 7.4153990e-01, 4.0991809e-03]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predictions)\n",
    "display(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Confusion Matrix function \n",
    "Sklearn function 'confusion_matrix(y_true, y_pred)' requires two array arguements with class labels in decimals. The two arrays are true labels and predictions. The function below maps the probabilitiesn or one hot encoded arrays to the required array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cargo': 0, 'tanker': 1, 'others': 2}\n",
      "[0, 0, 2, 2, 2, 0, 1, 2, 1, 0, 2, 2, 1, 2, 0, 1, 2, 2, 2, 2, 0]\n",
      "[0, 0, 2, 0, 2, 0, 1, 2, 2, 0, 2, 2, 0, 2, 0, 1, 1, 2, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "def predictions_to_label_array(predictions_array):\n",
    "    predictions_one_hot_encode = []\n",
    "    for array in predictions_array:\n",
    "        result_per__iteration = []\n",
    "        for value in array:\n",
    "            if value < max(array):\n",
    "                result_per__iteration.append(0)\n",
    "            elif value == max(array):\n",
    "                result_per__iteration.append(1)\n",
    "            else:\n",
    "                result_per__iteration.append(0)\n",
    "        predictions_one_hot_encode.append(result_per__iteration)\n",
    "    return([np.where(r==1)[0][0] for r in np.array(predictions_one_hot_encode)])\n",
    "prediction_label = predictions_to_label_array(predictions)\n",
    "true_label = predictions_to_label_array(test_labels)\n",
    "print('{}\\n{}\\n{}'.format(class_labels, true_label, prediction_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_label, prediction_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function has been copied from the Sklearn confusion matrix page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[5 1 0]\n",
      " [1 2 1]\n",
      " [1 1 9]]\n",
      "Confusion matrix, without normalization\n",
      "[[5 1 0]\n",
      " [1 2 1]\n",
      " [1 1 9]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = categories\n",
    "plot_confusion_matrix(cm, cm_plot_labels,\n",
    "                          title='Confusion matrix')\n",
    "\n",
    "plot_confusion_matrix(cm, classes=categories,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      cargo       0.71      0.83      0.77         6\n",
      "     tanker       0.50      0.50      0.50         4\n",
      "     others       0.90      0.82      0.86        11\n",
      "\n",
      "avg / total       0.77      0.76      0.76        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_label, prediction_label, target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model\n",
    "The method below will only work if keras version 2.1.6 or below is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_models/vgg16_model_ships.h5')#The architecture, weights, congig, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('saved_models/vgg16_model_ships.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
