{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all the necessary modules\n",
    "Make a conda environment and install Tensorflow 1.9.0, keras 2.1.6, OpenCV, and sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import optimizers, regularizers\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy import misc, ndimage\n",
    "from IPython.display import display, HTML\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_name = \"shi_detect_VGG-16-{}\".format(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_tensorboard = keras.callbacks.TensorBoard(log_dir='logs/{}'.format(TB_name))\n",
    "#write_graph=True, write_images=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lock the Random variables\n",
    ".seed functions allow us to reproduce the same results for each random initialization\n",
    "If the seed is set to the same number each time the program is run then the results of training the model will be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = '0' \n",
    "np.random.seed(10)\n",
    "random.seed(10)\n",
    "tf.set_random_seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helper function below for plotting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(ims, figsize = (12,6), rows = 1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize = figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to directories containing the image data, and the list of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"/home/hamza/hamzamk/Keras_work/Ship_images\"\n",
    "#categories1 = [\"cargo_RGB\", \"dredging_RGB\",  \"fishing_RGB\",  \"tanker_RGB\",  \"tug_RGB\"]\n",
    "categories = [\"cargo\", \"tanker\", \"others\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/hamza/hamzamk/Keras_work/Ship_images/train'\n",
    "valid_path = '/home/hamza/hamzamk/Keras_work/Ship_images/valid'\n",
    "test_path = '/home/hamza/hamzamk/Keras_work/Ship_images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11269 images belonging to 3 classes.\n",
      "Found 140 images belonging to 3 classes.\n",
      "Found 21 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size = (224, 224), color_mode='rgb', classes = categories, batch_size = 32, shuffle=True)\n",
    "valid_batches = ImageDataGenerator().flow_from_directory(valid_path, target_size = (224, 224), color_mode='rgb',  classes = categories, batch_size = 30, shuffle=True)\n",
    "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size = (224, 224),  color_mode='rgb', classes = categories, batch_size = 27, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the indices or lables assigned to each class by the ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cargo': 0, 'tanker': 1, 'others': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_imgs, test_labels = next(test_batches)\n",
    "class_labels = test_batches.class_indices\n",
    "class_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and check its structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model = keras.applications.vgg16.VGG16()\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.training.Model"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vgg16_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing VGG16\n",
    "iterate over the layers to feed the sequential model, set trainable to False to benefit from the pre-trained weights.\n",
    "Add layers to the model for fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers = []\n",
    "for layer in vgg16_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "    layers.append(layer)\n",
    "\n",
    "model = Sequential(layers + [\n",
    "    Conv2D(filters = 512, kernel_size = (7, 7), activation = 'relu'),\n",
    "    #Conv2D(filters = 512, kernel_size = (4,4), activation = 'relu'),\n",
    "    Flatten(),\n",
    "    BatchNormalization(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(2048, activation = 'relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(3, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 1, 512)         12845568  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              8390656   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 6147      \n",
      "=================================================================\n",
      "Total params: 38,060,355\n",
      "Trainable params: 23,344,643\n",
      "Non-trainable params: 14,715,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Compilation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adam = optimizers.Adam(lr=0.0001)\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33\n",
      "353/353 [==============================] - 45s 126ms/step - loss: 0.7729 - acc: 0.7430 - val_loss: 0.8053 - val_acc: 0.6857\n",
      "Epoch 2/33\n",
      "353/353 [==============================] - 41s 117ms/step - loss: 0.6110 - acc: 0.7614 - val_loss: 0.7679 - val_acc: 0.7071\n",
      "Epoch 3/33\n",
      "353/353 [==============================] - 40s 114ms/step - loss: 0.5829 - acc: 0.7700 - val_loss: 0.8585 - val_acc: 0.6643\n",
      "Epoch 4/33\n",
      "353/353 [==============================] - 40s 112ms/step - loss: 0.5387 - acc: 0.7861 - val_loss: 0.7854 - val_acc: 0.7357\n",
      "Epoch 5/33\n",
      "353/353 [==============================] - 40s 115ms/step - loss: 0.4938 - acc: 0.8021 - val_loss: 0.7382 - val_acc: 0.7143\n",
      "Epoch 6/33\n",
      "353/353 [==============================] - 40s 114ms/step - loss: 0.4263 - acc: 0.8278 - val_loss: 0.9764 - val_acc: 0.7286\n",
      "Epoch 7/33\n",
      "353/353 [==============================] - 41s 116ms/step - loss: 0.3795 - acc: 0.8458 - val_loss: 0.5093 - val_acc: 0.8429\n",
      "Epoch 8/33\n",
      "353/353 [==============================] - 41s 116ms/step - loss: 0.3495 - acc: 0.8612 - val_loss: 0.8113 - val_acc: 0.7429\n",
      "Epoch 9/33\n",
      "353/353 [==============================] - 42s 118ms/step - loss: 0.3100 - acc: 0.8763 - val_loss: 0.9516 - val_acc: 0.7786\n",
      "Epoch 10/33\n",
      "353/353 [==============================] - 41s 116ms/step - loss: 0.2875 - acc: 0.8837 - val_loss: 0.6439 - val_acc: 0.8714\n",
      "Epoch 11/33\n",
      "353/353 [==============================] - 41s 115ms/step - loss: 0.2556 - acc: 0.8985 - val_loss: 0.7483 - val_acc: 0.7929\n",
      "Epoch 12/33\n",
      "353/353 [==============================] - 41s 116ms/step - loss: 0.2308 - acc: 0.9098 - val_loss: 0.5915 - val_acc: 0.8786\n",
      "Epoch 13/33\n",
      "353/353 [==============================] - 41s 115ms/step - loss: 0.2008 - acc: 0.9211 - val_loss: 0.6744 - val_acc: 0.8500\n",
      "Epoch 14/33\n",
      "353/353 [==============================] - 41s 115ms/step - loss: 0.1867 - acc: 0.9231 - val_loss: 1.0320 - val_acc: 0.8357\n",
      "Epoch 15/33\n",
      "353/353 [==============================] - 41s 117ms/step - loss: 0.1664 - acc: 0.9364 - val_loss: 1.1789 - val_acc: 0.7857\n",
      "Epoch 16/33\n",
      "353/353 [==============================] - 41s 116ms/step - loss: 0.1465 - acc: 0.9425 - val_loss: 0.9614 - val_acc: 0.7857\n",
      "Epoch 17/33\n",
      "353/353 [==============================] - 41s 117ms/step - loss: 0.1365 - acc: 0.9493 - val_loss: 1.6049 - val_acc: 0.7429\n",
      "Epoch 18/33\n",
      "353/353 [==============================] - 41s 117ms/step - loss: 0.1247 - acc: 0.9534 - val_loss: 0.9782 - val_acc: 0.8286\n",
      "Epoch 19/33\n",
      "353/353 [==============================] - 41s 117ms/step - loss: 0.1061 - acc: 0.9620 - val_loss: 1.4836 - val_acc: 0.7357\n",
      "Epoch 20/33\n",
      "353/353 [==============================] - 41s 117ms/step - loss: 0.1247 - acc: 0.9540 - val_loss: 1.0264 - val_acc: 0.8286\n",
      "Epoch 21/33\n",
      "353/353 [==============================] - 41s 117ms/step - loss: 0.1078 - acc: 0.9608 - val_loss: 1.0318 - val_acc: 0.8786\n",
      "Epoch 22/33\n",
      "353/353 [==============================] - 42s 118ms/step - loss: 0.1034 - acc: 0.9626 - val_loss: 1.0625 - val_acc: 0.8143\n",
      "Epoch 23/33\n",
      "353/353 [==============================] - 42s 118ms/step - loss: 0.1115 - acc: 0.9607 - val_loss: 0.9326 - val_acc: 0.8357\n",
      "Epoch 24/33\n",
      "353/353 [==============================] - 41s 117ms/step - loss: 0.0912 - acc: 0.9677 - val_loss: 1.1467 - val_acc: 0.8286\n",
      "Epoch 25/33\n",
      "353/353 [==============================] - 42s 118ms/step - loss: 0.0710 - acc: 0.9752 - val_loss: 0.7104 - val_acc: 0.8571\n",
      "Epoch 26/33\n",
      "353/353 [==============================] - 41s 117ms/step - loss: 0.0634 - acc: 0.9764 - val_loss: 1.2797 - val_acc: 0.8143\n",
      "Epoch 27/33\n",
      "353/353 [==============================] - 42s 118ms/step - loss: 0.0588 - acc: 0.9796 - val_loss: 1.6636 - val_acc: 0.7714\n",
      "Epoch 28/33\n",
      "353/353 [==============================] - 42s 118ms/step - loss: 0.0736 - acc: 0.9730 - val_loss: 0.8962 - val_acc: 0.8714\n",
      "Epoch 29/33\n",
      " 67/353 [====>.........................] - ETA: 32s - loss: 0.0585 - acc: 0.9804"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-6e7080da7045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                    \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcall_tensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                    verbose = 1)\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_batches,\n",
    "                   validation_data = valid_batches,\n",
    "                   shuffle = True,\n",
    "                   callbacks = [call_tensorboard],  \n",
    "                   epochs = 33,\n",
    "                   verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on test data for Predictions\n",
    "The predictions will be displayed in scientific notation, e.g. 9.9989974e-01 in decimal is 0.99. This indicates high probability for the detected object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 1s 638ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(test_batches, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block below will only work if HTML and display have been imported in the first block, This will allow us to use CSS formating for comparitive content display on jupyter notebook. For viewing normal outputs, use the print function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output{\n",
       "    flex-direction: row;\n",
       "    \n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSS = \"\"\"\n",
    ".output{\n",
    "    flex-direction: row;\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "HTML('<style>{}</style>'.format(CSS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.6114444e-06, 9.6214590e-12, 9.9999833e-01],\n",
       "       [1.0000000e+00, 3.2077778e-12, 4.5091265e-15],\n",
       "       [9.9956304e-01, 1.7662467e-04, 2.6033030e-04],\n",
       "       [1.7849238e-04, 4.3069616e-05, 9.9977845e-01],\n",
       "       [9.5152724e-01, 2.3473077e-02, 2.4999732e-02],\n",
       "       [3.7061454e-06, 9.9953830e-01, 4.5804479e-04],\n",
       "       [1.0000000e+00, 6.4009836e-10, 9.2594812e-13],\n",
       "       [6.9896792e-08, 2.8171081e-08, 9.9999988e-01],\n",
       "       [4.2317063e-03, 9.9468404e-01, 1.0842247e-03],\n",
       "       [8.7164764e-10, 3.4707792e-11, 1.0000000e+00],\n",
       "       [3.2371517e-08, 1.0897545e-08, 1.0000000e+00],\n",
       "       [5.8430567e-07, 6.3363387e-07, 9.9999881e-01],\n",
       "       [9.9914038e-01, 8.4847101e-04, 1.1086841e-05],\n",
       "       [7.9241392e-05, 9.1910057e-05, 9.9982882e-01],\n",
       "       [9.8185229e-01, 2.6360898e-05, 1.8121421e-02],\n",
       "       [6.4109099e-07, 5.6030625e-08, 9.9999928e-01],\n",
       "       [2.8406311e-04, 1.9633686e-02, 9.8008221e-01],\n",
       "       [9.7389865e-01, 2.0049054e-02, 6.0523096e-03],\n",
       "       [9.4019639e-01, 5.9789803e-02, 1.3830161e-05],\n",
       "       [9.9999988e-01, 1.2355585e-07, 3.6168002e-10],\n",
       "       [7.4227405e-04, 9.4459158e-01, 5.4666143e-02]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predictions)\n",
    "display(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Confusion Matrix function \n",
    "Sklearn function 'confusion_matrix(y_true, y_pred)' requires two array arguements with class labels in decimals. The two arrays are true labels and predictions. The function below maps the probabilitiesn or one hot encoded arrays to the required array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cargo': 0, 'tanker': 1, 'others': 2}\n",
      "[2, 0, 0, 2, 1, 2, 0, 2, 1, 2, 2, 2, 1, 2, 0, 2, 2, 0, 2, 0, 1]\n",
      "[2, 0, 0, 2, 0, 1, 0, 2, 1, 2, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "def predictions_to_label_array(predictions_array):\n",
    "    predictions_one_hot_encode = []\n",
    "    for array in predictions_array:\n",
    "        result_per__iteration = []\n",
    "        for value in array:\n",
    "            if value < max(array):\n",
    "                result_per__iteration.append(0)\n",
    "            elif value == max(array):\n",
    "                result_per__iteration.append(1)\n",
    "            else:\n",
    "                result_per__iteration.append(0)\n",
    "        predictions_one_hot_encode.append(result_per__iteration)\n",
    "    return([np.where(r==1)[0][0] for r in np.array(predictions_one_hot_encode)])\n",
    "prediction_label = predictions_to_label_array(predictions)\n",
    "true_label = predictions_to_label_array(test_labels)\n",
    "print('{}\\n{}\\n{}'.format(class_labels, true_label, prediction_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_label, prediction_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function has been copied from the Sklearn confusion matrix page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[6 0 0]\n",
      " [2 2 0]\n",
      " [1 1 9]]\n",
      "Confusion matrix, without normalization\n",
      "[[6 0 0]\n",
      " [2 2 0]\n",
      " [1 1 9]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = categories\n",
    "plot_confusion_matrix(cm, cm_plot_labels,\n",
    "                          title='Confusion matrix')\n",
    "\n",
    "plot_confusion_matrix(cm, classes=categories,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      cargo       0.67      1.00      0.80         6\n",
      "     tanker       0.67      0.50      0.57         4\n",
      "     others       1.00      0.82      0.90        11\n",
      "\n",
      "avg / total       0.84      0.81      0.81        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_label, prediction_label, target_names=categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model\n",
    "The method below will only work if keras version 2.1.6 or below is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_models/vgg16_model_ships.h5')#The architecture, weights, congig, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('saved_models/vgg16_model_ships.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
